{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 03:28:30.273228: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 03:28:30.297736: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 03:28:30.664185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['#', 'type', 'text', 'aggregatedAnnotation',\n",
       "       'aggregatedAnnotationConfidence', 'annotator1', 'annotator2',\n",
       "       'annotator3'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>aggregatedAnnotation</th>\n",
       "      <th>aggregatedAnnotationConfidence</th>\n",
       "      <th>annotator1</th>\n",
       "      <th>annotator2</th>\n",
       "      <th>annotator3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TWEET</td>\n",
       "      <td>مبروك و سامحونا لعجزنا التام. عقبال اللي جوه. اللي بره يا عاجز يا بيزايد على العاجز</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C1</td>\n",
       "      <td>كلنا بره ومش هنبطل نزايد على العجايز الي جابونا ورى</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C2</td>\n",
       "      <td>بدل ما انت قاعد بره كده تعالي ازرع الصحرا</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C3</td>\n",
       "      <td>قذر اتفووو ماتيجى مصر وتورينا نفسك كدا ياجبان</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #   type   \n",
       "0  1  TWEET  \\\n",
       "1  2     C1   \n",
       "2  3     C2   \n",
       "3  4     C3   \n",
       "\n",
       "                                                                                  text   \n",
       "0  مبروك و سامحونا لعجزنا التام. عقبال اللي جوه. اللي بره يا عاجز يا بيزايد على العاجز  \\\n",
       "1                                  كلنا بره ومش هنبطل نزايد على العجايز الي جابونا ورى   \n",
       "2                                            بدل ما انت قاعد بره كده تعالي ازرع الصحرا   \n",
       "3                                        قذر اتفووو ماتيجى مصر وتورينا نفسك كدا ياجبان   \n",
       "\n",
       "   aggregatedAnnotation  aggregatedAnnotationConfidence  annotator1   \n",
       "0                     0                          0.6667          -1  \\\n",
       "1                    -1                          0.6667          -1   \n",
       "2                     0                          1.0000           0   \n",
       "3                    -1                          1.0000          -1   \n",
       "\n",
       "   annotator2  annotator3  \n",
       "0           0           0  \n",
       "1          -1           0  \n",
       "2           0           0  \n",
       "3          -1          -1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{-2, -1, 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 880\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 220\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>0.817393</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.658798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.596806</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.777083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.455500</td>\n",
       "      <td>0.532017</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.778150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.311100</td>\n",
       "      <td>0.569369</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.774077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.617054</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.753095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.628827</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.787248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.749499</td>\n",
       "      <td>0.786364</td>\n",
       "      <td>0.779547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.872076</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.753298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>0.879154</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.759584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.964468</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.750418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.972450</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.787320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.031251</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.779483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>1.127333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.096686</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.760647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.155943</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.223234</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.742513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.163693</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.765067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.186107</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.770299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.188672</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.768560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.206558</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.765797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.345104</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.734587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.370891</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.734587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.272360</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.773453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.299158</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.303429</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.765797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.328387</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.346505</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.355910</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.744228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.374541</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.755834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.379071</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.755834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.380854</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.744228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.382106</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.740358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.382772</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.744228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.383241</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.744228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.383543</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.744228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.776543</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.641898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.590815</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.762792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.556274</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.768596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.284900</td>\n",
       "      <td>0.641637</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.754865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.761294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.120900</td>\n",
       "      <td>0.742842</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.757255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.955932</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.768435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.026879</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>1.121678</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.737396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.144067</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.757715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.186129</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.770369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.230549</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.758030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.277629</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.745977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.303817</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.746609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.352962</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.761814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.356615</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.769275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.365736</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.764490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.396698</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.751758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.430950</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.765492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.444738</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.457983</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.440022</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.757645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.481266</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.458708</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.451548</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.765287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.453192</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.761946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.459212</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.764468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.464265</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.758132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.476298</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.476885</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.479102</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.480308</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.481315</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.482024</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.482075</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.776543</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.641898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.590815</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.762792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.556274</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.768596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.284900</td>\n",
       "      <td>0.641637</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.754865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.761294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.120900</td>\n",
       "      <td>0.742842</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.757255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.955932</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.768435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.026879</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>1.121678</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.737396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.144067</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.757715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.186129</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.770369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.230549</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.758030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.277629</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.745977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.303817</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.746609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.352962</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.761814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.356615</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.769275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.365736</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.764490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.396698</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.751758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.430950</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.765492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.444738</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.457983</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.440022</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.757645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.481266</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.458708</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.451548</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.765287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.453192</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.761946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.459212</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.764468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.464265</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.758132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.476298</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.476885</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.479102</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.480308</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.481315</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.482024</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.482075</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:29, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.020600</td>\n",
       "      <td>0.846237</td>\n",
       "      <td>0.631818</td>\n",
       "      <td>0.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.689966</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.693234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.658861</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.734611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.647086</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.734881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.813244</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.741643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.881348</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.755139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>1.135765</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.734595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>1.236455</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>1.210595</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>1.184123</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.241440</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.733032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>1.310048</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.733072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>1.253298</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.736184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.307125</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.760356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.271548</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.739396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>1.321224</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.743175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.369902</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.747935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.564872</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.721750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.475838</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.744585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.472396</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.739771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.464010</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.746865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.522358</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.726141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.498710</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.487964</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.721172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.474283</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.720361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.468238</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.728290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.474823</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.729959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.512276</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.739594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.536285</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.730248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.529069</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.741411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.519935</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.517621</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.517522</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.516893</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:29, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.020600</td>\n",
       "      <td>0.846237</td>\n",
       "      <td>0.631818</td>\n",
       "      <td>0.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.689966</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.693234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.658861</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.734611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.647086</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.734881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.813244</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.741643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.881348</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.755139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>1.135765</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.734595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>1.236455</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>1.210595</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>1.184123</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.241440</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.733032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>1.310048</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.733072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>1.253298</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.736184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.307125</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.760356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.271548</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.739396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>1.321224</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.743175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.369902</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.747935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.564872</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.721750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.475838</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.744585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.472396</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.739771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.464010</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.746865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.522358</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.726141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.498710</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.487964</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.721172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.474283</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.720361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.468238</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.728290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.474823</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.729959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.512276</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.739594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.536285</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.730248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.529069</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.741411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.519935</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.517621</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.517522</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.516893</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:29, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.020600</td>\n",
       "      <td>0.846237</td>\n",
       "      <td>0.631818</td>\n",
       "      <td>0.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.689966</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.693234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.658861</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.734611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.647086</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.734881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.813244</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.741643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.881348</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.755139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>1.135765</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.734595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>1.236455</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>1.210595</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>1.184123</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.241440</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.733032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>1.310048</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.733072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>1.253298</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.736184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.307125</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.760356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.271548</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.739396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>1.321224</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.743175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.369902</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.747935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.564872</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.721750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.475838</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.744585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.472396</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.739771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.464010</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.746865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.522358</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.726141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.498710</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.487964</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.721172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.474283</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.720361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.468238</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.728290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.474823</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.729959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.512276</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.739594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.536285</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.730248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.529069</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.741411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.519935</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.517621</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.517522</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.516893</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.742278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.735630</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.662158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.599245</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.568827</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.756312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.739420</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.735324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.802928</td>\n",
       "      <td>0.786364</td>\n",
       "      <td>0.786909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.880606</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.986144</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.741189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.102146</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>1.289267</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.722287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.228429</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.777055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>1.168815</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.777201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.118937</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.791055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.331590</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.262798</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.738043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.326723</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.458505</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.736271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.553418</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.740205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.520957</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>0.720274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.479881</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.735854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.463246</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.733977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.357169</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.771572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.504061</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.728719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.455366</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.454496</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.745396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.476970</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.751685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.481904</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.755567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.481794</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.502277</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.755397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.501684</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.502111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.528345</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.741116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.540144</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.547080</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.550072</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.551205</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.735630</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.662158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.599245</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.568827</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.756312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.739420</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.735324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.802928</td>\n",
       "      <td>0.786364</td>\n",
       "      <td>0.786909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.880606</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.986144</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.741189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.102146</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>1.289267</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.722287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.228429</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.777055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>1.168815</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.777201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.118937</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.791055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.331590</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.262798</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.738043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.326723</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.458505</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.736271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.553418</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.740205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.520957</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>0.720274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.479881</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.735854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.463246</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.733977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.357169</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.771572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.504061</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.728719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.455366</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.454496</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.745396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.476970</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.751685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.481904</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.755567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.481794</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.502277</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.755397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.501684</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.502111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.528345</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.741116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.540144</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.547080</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.550072</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.551205</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235a4efc3f164a97951f1493c44b0095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.735630</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.662158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.599245</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.568827</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.756312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.739420</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.735324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.802928</td>\n",
       "      <td>0.786364</td>\n",
       "      <td>0.786909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.880606</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.986144</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.741189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.102146</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>1.289267</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.722287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.228429</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.777055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>1.168815</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.777201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.118937</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.791055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.331590</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.262798</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.738043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.326723</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.458505</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.736271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.553418</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.740205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.520957</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>0.720274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.479881</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.735854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.463246</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.733977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.357169</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.771572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.504061</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.728719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.455366</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.454496</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.745396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.476970</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.751685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.481904</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.755567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.481794</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.502277</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.755397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.501684</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.502111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.528345</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.741116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.540144</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.547080</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.550072</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.551205</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.734219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAMeL-Lab/bert-base-arabic-camelbert-da</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.760921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aubmindlab/bert-base-arabertv02-twitter</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.787320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qarib/bert-base-qarib</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.791055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Accuracy        F1\n",
       "0  CAMeL-Lab/bert-base-arabic-camelbert-da  0.759091  0.760921\n",
       "3  aubmindlab/bert-base-arabertv02-twitter  0.790909  0.787320\n",
       "4                    qarib/bert-base-qarib  0.790909  0.791055"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'Abusive_mubarak17_1.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('datasets/Abusive_mubarak17.csv', encoding='utf-8', engine='python') #, sep='\\t' , quotechar=\"'\"  , quoting=3\n",
    "display(df.columns)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "display(df[:4])\n",
    "\n",
    "\n",
    "\n",
    "df = df[df['text'] != '']\n",
    "\n",
    "classes = set(df['aggregatedAnnotation'].values)\n",
    "display(classes)\n",
    "\n",
    "df['aggregatedAnnotation'] = df['aggregatedAnnotation'].astype('category')\n",
    "df['label'] = df['aggregatedAnnotation'].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "\n",
    "\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'aubmindlab/bert-base-arabertv02-twitter',\n",
    "        'CAMeL-Lab/bert-base-arabic-camelbert-da',\n",
    "        'qarib/bert-base-qarib',  \n",
    "]\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                    \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['text'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length, add_special_tokens=True)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "            \n",
    "        epochs = 25\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 64\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 10, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 10\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('Abusive_mubarak17_results_1.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db6f4ec-e6be-4eaf-8171-913e9ec11e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604249b-3df4-48bf-962d-b14d3911709b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f6179-e8f0-4e55-888e-d38cc70a6cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354374a-7d4d-48f5-8ced-1784ef469388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
